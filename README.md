# PN_DorsalNet
In silico physiology of DorsalNet units.

This repository contains code for analyzing visual neuronal responses using DorsalNet, a 6-layer 3D convolutional neural network trained to predict simulated self-motion parameters from visual input. The model was trained on short videos generated with the AirSim package, simulating various environmental conditions. We used a pre-trained DorsalNet model to run simulated experiments, feeding it drifting gratings and plaids moving in 12 equispaced directions at fixed spatial and temporal frequencies. The analysis pipeline, applied to both DorsalNet and neuronal recordings, involved building direction tuning curves and classifying network units as either pattern or component. Spatiotemporally correlated noise movies were also used, with spatial and temporal correlation scales choosen to match neurophysiological conditions. Activations were sampled from the center of each convolutional map at the output layer of each network block. The pre-trained model checkpoint is provided by Mineault et al. (“airsim_dorsalnet_batch2_model.ckpt-3174400-2021-02-12 02-03-1690 29.666899.pt”), who demonstrated its effectiveness in explaining primate dorsal stream neural responses.

To run the code, first run the "download_activations_and_stimuli_PN.m" script to download stimuli and units activations from GoogleDrive.
