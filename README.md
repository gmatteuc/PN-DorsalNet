# PN_DorsalNet
In silico physiology of DorsalNet units.

This repository contains code for analyzing visual neuronal responses using DorsalNet, a 6-layer 3D convolutional neural network trained to predict simulated self-motion parameters from visual input. The model was trained on short videos generated with the AirSim package, simulating various environmental conditions. We used a pre-trained DorsalNet model to run simulated experiments, feeding it drifting gratings and plaids moving in 12 equispaced directions at fixed spatial and temporal frequencies. The analysis pipeline, applied to both DorsalNet and neuronal recordings in our Science Advances paper, involved building direction tuning curves and classifying network units as either pattern or component. Spatiotemporally correlated noise movies were also used, with spatial and temporal correlation scales chosen to match the extracellular electrophysiology experiments in rats. Activations were sampled from the center of each convolutional map at the output layer of each network block. The pre-trained model checkpoint is provided by Mineault et al. (“airsim_dorsalnet_batch2_model.ckpt-3174400-2021-02-12 02-03-1690 29.666899.pt”), who demonstrated its effectiveness in explaining primate dorsal stream neural responses.

Refer to the 2023 *Science Advances* publication: *"Truly pattern: Nonlinear integration of motion signals is required to account for the responses of pattern cells in rat visual cortex"* (<https://www.science.org/doi/10.1126/sciadv.adh4690>) for analyses results.

To run the code, first run the "download_activations_and_stimuli_PN.m" script to download stimuli and units activations from GoogleDrive.
